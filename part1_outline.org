#+TITLE: Part1 Outline


* TODOS
** Problem Formulation
*** DONE Formulate the problem

*** DONE Data points must be explicitly explained
*** DONE Dataset must be multidimensional

*** DONE Explain where data is from
*** DONE Explain the type of data

*** DONE Explain the typ of ml (un or supervised)
-> explain labels if supervised

** Methods

*** DONE state number of datapoints and the processing

*** DONE explain feature selection/engineering(processing)

*** TODO state the model (hypothesis space)
*** TODO explain choice of model (see ml book)

*** TODO state loss function
*** TODO explain choice of loss function? (see ml book)

*** TODO explain process of model validation
*** TODO explain the split of data in training/validation
*** TODO state the size of the sets
*** TODO explain these choices


* TODOs
Which method to use?
Explain why this model
Which loss function
Explain why this function
How to split data in training/validation





** Miscellaneous
*** TODO Code
*** TODO Quality of writing
*** TODO Sources no plagiarism






* Notes
Data prep
    take most important features -> no overfitting

    log reg -> standardise (prevent overfitting)


Splitting data
    - should use k-fold !!
    - just 0.2% as optimal random split
    - 3 parts
        2 for training/validation
        1 for error calculation


Loss function
    Logistic
    -> log loss |


    SVC
    -> log loss |
    -> hinge loss (-1/1)



clf = LogisticRegression()
poly = PolynomialFeatures(3)
X_poly = poly.fit_transform(X)
scaler = preprocessing.StandardScaler().fit(X_poly)
X_poly = scaler.transform(X_poly) #scale the transformed features
clf.fit(X_poly, y) #train model with X and y
#transform X_test into polynomials, scale and make a prediction
X_test_poly = poly.transform(X_test)
X_test_poly = scaler.transform(X_test_poly)
y_pred_test = clf.predict(X_test_poly) #predict!
